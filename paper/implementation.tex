To play \ispy, we first gathered sensory data from the set of objects through robot manipulation behaviors (described in Section~\ref{sec:dataset}).
When playing a game, the robot was given unique identifying numbers for each object on the table and could look up relevant feature vectors when performing grounding.

During the course of the game, the robot used its RGBD camera to detect the locations of the objects and subsequently detect whenever a human reached out and touched an object in response to the robot's turn.
The robot was also equipped with the ability to reach out and point to an object when it was the robot's turn to guess.
We implemented robot behaviors in the Robot Operating System\footnote{\texttt{http://www.ros.org/}} and performed text-to-speech using the Festival Speech Synthesis System\footnote{\texttt{http://www.cstr.ed.ac.uk/projects/festival/}}.